{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS247 Advanced Data Mining - Assignment 5\n",
    "## Deadline: 11:59PM, February 28, 2023\n",
    "\n",
    "## Instructions\n",
    "Each assignment is structured as a Jupyter notebook, offering interactive tutorials that align with our lectures. You will encounter two types of problems: *write-up problems* and *coding problems*.\n",
    "\n",
    "1. **Write-up Problems:** These problems are primarily theoretical, requiring you to demonstrate your understanding of lecture concepts and to provide mathematical proofs for key theorems. Your answers should include sufficient steps for the mathematical derivations.\n",
    "2. **Coding Problems:** Here, you will be engaging with practical coding tasks. These may involve completing code segments provided in the notebooks or developing models from scratch.\n",
    "\n",
    "To ensure clarity and consistency in your submissions, please adhere to the following guidelines:\n",
    "\n",
    "* For write-up problems, use Markdown bullet points to format text answers. Also, express all mathematical equations using $\\LaTeX$ and avoid plain text such as `x0`, `x^1`, or `R x Q` for equations.\n",
    "* For coding problems, comment on your code thoroughly for readability and ensure your code is executable. Non-runnable code may lead to a loss of **all** points. Coding problems have automated grading, and altering the grading code will result in a deduction of **all** points.\n",
    "* Your submission should show the entire process of data loading, preprocessing, model implementation, training, and result analysis. This can be achieved through a mix of explanatory text cells, inline comments, intermediate result displays, and experimental visualizations.\n",
    "\n",
    "### Submission Requirements\n",
    "\n",
    "* Submit your solutions through GradeScope in BruinLearn.\n",
    "* Late submissions are allowed up to 24 hours post-deadline with a penalty factor of $\\mathbf{1}(t\\leq24)e^{-(\\ln(2)/12)t}$.\n",
    "\n",
    "### Collaboration and Integrity\n",
    "\n",
    "* Collaboration is encouraged, but all final submissions must be your own work. Please acknowledge any collaboration or external sources used, including websites, papers, and GitHub repositories.\n",
    "* Any suspicious cases of academic misconduct will be reported to The Office of the Dean of Students.\n",
    "\n",
    "## Outline\n",
    "* Problem 1: Network Embedding\n",
    "* Problem 2: Knowledge Graph Embedding\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Node Embedding - LINE (40 pts = 20 + 20)\n",
    "\n",
    "\n",
    "In this problem, you are going to implement the __First-order LINE__ (finish contrastive loss, negative sampling and training pipleline). Get embedding of karate graph, then visualize your results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sb\n",
    "import networkx as nx # new dependency \n",
    "import numpy as np\n",
    "from scipy.linalg import sqrtm\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and set parameters\n",
    "\n",
    "G = nx.karate_club_graph()\n",
    "edges  = np.array(list(G.edges))\n",
    "degree = dict(G.degree)\n",
    "true_labels = np.zeros(len(G.nodes))\n",
    "for i in range(len(true_labels)):\n",
    "    if G.nodes[i]['club']=='Officer':\n",
    "        true_labels[i]=1\n",
    "\n",
    "n_epochs = 100\n",
    "neg_size = 5\n",
    "batchrange = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line(nn.Module):\n",
    "    def __init__(self, size, embed_dim=128):\n",
    "        super(Line, self).__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.nodes_embeddings = nn.Embedding(size, embed_dim)\n",
    "\n",
    "        # Initialization\n",
    "        self.nodes_embeddings.weight.data = self.nodes_embeddings.weight.data.uniform_(-.5, .5) / embed_dim\n",
    "\n",
    "    def loss(self, v_i, v_j, negsamples):\n",
    "        '''\n",
    "        TODO:\n",
    "            implement contrastive loss here\n",
    "        '''\n",
    "\n",
    "        pos_i =  self.nodes_embeddings(v_i)\n",
    "\n",
    "\n",
    "        pos_j =  self.nodes_embeddings(v_j)\n",
    "        neg_samples = self.nodes_embeddings(negsamples)\n",
    "\n",
    "#         print(\"pos_i dim: \", pos_i.shape)\n",
    "#         print(\"pos_j dim: \", pos_j.shape)\n",
    "#         print(\"neg_samples dim: \", neg_samples.shape)\n",
    "\n",
    "        #calculate the positive part of the loss function\n",
    "        pos_score = torch.mul(pos_i, pos_j)\n",
    "#         print(\"pos_score dim: \", pos_score.shape)\n",
    "        pos_score = torch.sum(pos_score,dim = 1)\n",
    "        pos_log = F.logsigmoid(pos_score)\n",
    "\n",
    "\n",
    "        #calculate the negative sample part of the loss function\n",
    "        neg_score = torch.mul(pos_i.view(len(pos_i), 1, self.embed_dim), neg_samples)\n",
    "        neg_score = torch.sum(neg_score, dim=2)\n",
    "        neg_log = F.logsigmoid(-1*neg_score)\n",
    "        neg_log = torch.sum(neg_log, dim=1)\n",
    "\n",
    "        loss = pos_log + neg_log\n",
    "\n",
    "        return -torch.mean(loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     generating batches of data.\n",
    "\n",
    "def makeData(samplededges, negsamplesize, degree):\n",
    "    sampledNodes = set()\n",
    "    nodesProb = []\n",
    "    sumofDegree = 0\n",
    "    for e in samplededges:\n",
    "        sampledNodes.add(e[0])\n",
    "        sampledNodes.add(e[1])\n",
    "    sampledNodes = list(sampledNodes)\n",
    "    nodesProb = [pow(degree[v],3/4) for v in sampledNodes]\n",
    "    sumofDegree = sum(nodesProb)\n",
    "    nodesProb[:] = [x/sumofDegree for x in nodesProb]\n",
    "\n",
    "    for e in samplededges:\n",
    "        sourcenode, targetnode = e[0], e[1]\n",
    "        negnodes = []\n",
    "        negsamples = 0\n",
    "        while negsamples < negsamplesize:\n",
    "            '''\n",
    "            TODO:\n",
    "                Randomly sampled negative nodes based on degree (d^{3/4})\n",
    "            '''\n",
    "            samplednode = np.random.choice(sampledNodes, p = nodesProb)\n",
    "            if (samplednode == sourcenode) or (samplednode == targetnode):\n",
    "                continue\n",
    "            else:\n",
    "                negsamples += 1\n",
    "                negnodes += [samplednode]\n",
    "        yield [e[0], e[1]] + negnodes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "line = Line(len(G), embed_dim=100)\n",
    "opt = optim.Adam(line.parameters())\n",
    "for epoch in range(n_epochs):\n",
    "    for b in trange(batchrange):\n",
    "        opt.zero_grad()\n",
    "        edge_idx = np.random.choice(len(edges), 10)\n",
    "        samplededges = edges[edge_idx]\n",
    "\n",
    "        batch = list(makeData(samplededges, neg_size, degree))\n",
    "        batch = torch.LongTensor(batch)\n",
    "\n",
    "        # based on the generated batch, train LINE via minimizing the loss.\n",
    "        v_i = batch[:,0]\n",
    "        v_j = batch[:,1]\n",
    "        negsamples =  batch[:,2:]\n",
    "        loss = line.loss(v_i, v_j, negsamples)\n",
    "        loss.backward()\n",
    "        opt.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSNE visualization, with node id on\n",
    "\n",
    "emb  = line.nodes_embeddings.weight.data.numpy()\n",
    "tsne_emb = TSNE(n_components = 2, perplexity = 5, learning_rate = 10, random_state=1).fit_transform(emb)\n",
    "\n",
    "plt.scatter(tsne_emb[:,0], tsne_emb[:,1], c=true_labels)\n",
    "for i in range(len(tsne_emb)):\n",
    "    plt.annotate(str(i), xy=(tsne_emb[i,0], tsne_emb[i,1]))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap visualization, check cosine similarities between all pair of nodes\n",
    "res = cosine_similarity(emb)\n",
    "\n",
    "sb.clustermap(res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Knowledge Graph Embedding (60 pts)\n",
    "\n",
    "In this assignment, we implement the simple KG embedding algorithm of TransE, DistMult, and RotateE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading (10 pts)\n",
    "This section contains the boilerplate code for data loading and dataset construction (__DO NOT MODIFY THIS PART__) unless in the TODO section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, triples, nentity, nrelation, negative_sample_size, mode):\n",
    "        self.len = len(triples)\n",
    "        self.triples = triples\n",
    "        self.triple_set = set(triples)\n",
    "        self.nentity = nentity\n",
    "        self.nrelation = nrelation\n",
    "        self.negative_sample_size = negative_sample_size\n",
    "        self.mode = mode\n",
    "        self.count = self.count_frequency(triples)\n",
    "        self.true_head, self.true_tail = self.get_true_head_and_tail(self.triples)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        positive_sample = self.triples[idx]\n",
    "\n",
    "        head, relation, tail = positive_sample\n",
    "\n",
    "        subsampling_weight = self.count[(head, relation)] + self.count[(tail, -relation-1)]\n",
    "        subsampling_weight = torch.sqrt(1 / torch.Tensor([subsampling_weight]))\n",
    "        \n",
    "        negative_sample_list = []\n",
    "        negative_sample_size = 0\n",
    "\n",
    "        while negative_sample_size < self.negative_sample_size:\n",
    "            negative_sample = np.random.randint(self.nentity, size=self.negative_sample_size*2)\n",
    "            if self.mode == 'head-batch':\n",
    "                mask = np.in1d(\n",
    "                    negative_sample, \n",
    "                    self.true_head[(relation, tail)], \n",
    "                    assume_unique=True, \n",
    "                    invert=True\n",
    "                )\n",
    "            elif self.mode == 'tail-batch':\n",
    "                mask = np.in1d(\n",
    "                    negative_sample, \n",
    "                    self.true_tail[(head, relation)], \n",
    "                    assume_unique=True, \n",
    "                    invert=True\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError('Training batch mode %s not supported' % self.mode)\n",
    "            negative_sample = negative_sample[mask]\n",
    "            negative_sample_list.append(negative_sample)\n",
    "            negative_sample_size += negative_sample.size\n",
    "        \n",
    "        negative_sample = np.concatenate(negative_sample_list)[:self.negative_sample_size]\n",
    "\n",
    "        negative_sample = torch.LongTensor(negative_sample)\n",
    "\n",
    "        positive_sample = torch.LongTensor(positive_sample)\n",
    "            \n",
    "        return positive_sample, negative_sample, subsampling_weight, self.mode\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(data):\n",
    "        positive_sample = torch.stack([_[0] for _ in data], dim=0)\n",
    "        negative_sample = torch.stack([_[1] for _ in data], dim=0)\n",
    "        subsample_weight = torch.cat([_[2] for _ in data], dim=0)\n",
    "        mode = data[0][3]\n",
    "        return positive_sample, negative_sample, subsample_weight, mode\n",
    "    \n",
    "    @staticmethod\n",
    "    def count_frequency(triples, start=4):\n",
    "        '''\n",
    "        Get frequency of a partial triple like (head, relation) or (relation, tail)\n",
    "        The frequency will be used for subsampling like word2vec\n",
    "        '''\n",
    "        count = {}\n",
    "        for head, relation, tail in triples:\n",
    "            if (head, relation) not in count:\n",
    "                count[(head, relation)] = start\n",
    "            else:\n",
    "                count[(head, relation)] += 1\n",
    "\n",
    "            if (tail, -relation-1) not in count:\n",
    "                count[(tail, -relation-1)] = start\n",
    "            else:\n",
    "                count[(tail, -relation-1)] += 1\n",
    "        return count\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_true_head_and_tail(triples):\n",
    "        '''\n",
    "        Build a dictionary of true triples that will\n",
    "        be used to filter these true triples for negative sampling\n",
    "        '''\n",
    "        \n",
    "        true_head = {}\n",
    "        true_tail = {}\n",
    "\n",
    "        for head, relation, tail in triples:\n",
    "            if (head, relation) not in true_tail:\n",
    "                true_tail[(head, relation)] = []\n",
    "            true_tail[(head, relation)].append(tail)\n",
    "            if (relation, tail) not in true_head:\n",
    "                true_head[(relation, tail)] = []\n",
    "            true_head[(relation, tail)].append(head)\n",
    "\n",
    "        for relation, tail in true_head:\n",
    "            true_head[(relation, tail)] = np.array(list(set(true_head[(relation, tail)])))\n",
    "        for head, relation in true_tail:\n",
    "            true_tail[(head, relation)] = np.array(list(set(true_tail[(head, relation)])))                 \n",
    "\n",
    "        return true_head, true_tail\n",
    "\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, triples, all_true_triples, nentity, nrelation, mode):\n",
    "        self.len = len(triples)\n",
    "        self.triple_set = set(all_true_triples)\n",
    "        self.triples = triples\n",
    "        self.nentity = nentity\n",
    "        self.nrelation = nrelation\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        head, relation, tail = self.triples[idx]\n",
    "\n",
    "        if self.mode == 'head-batch':\n",
    "            tmp = [(0, rand_head) if (rand_head, relation, tail) not in self.triple_set\n",
    "                   else (-1, head) for rand_head in range(self.nentity)]\n",
    "            tmp[head] = (0, head)\n",
    "        elif self.mode == 'tail-batch':\n",
    "            tmp = [(0, rand_tail) if (head, relation, rand_tail) not in self.triple_set\n",
    "                   else (-1, tail) for rand_tail in range(self.nentity)]\n",
    "            tmp[tail] = (0, tail)\n",
    "        else:\n",
    "            raise ValueError('negative batch mode %s not supported' % self.mode)\n",
    "            \n",
    "        tmp = torch.LongTensor(tmp)            \n",
    "        filter_bias = tmp[:, 0].float()\n",
    "        negative_sample = tmp[:, 1]\n",
    "\n",
    "        positive_sample = torch.LongTensor((head, relation, tail))\n",
    "            \n",
    "        return positive_sample, negative_sample, filter_bias, self.mode\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(data):\n",
    "        positive_sample = torch.stack([_[0] for _ in data], dim=0)\n",
    "        negative_sample = torch.stack([_[1] for _ in data], dim=0)\n",
    "        filter_bias = torch.stack([_[2] for _ in data], dim=0)\n",
    "        mode = data[0][3]\n",
    "        return positive_sample, negative_sample, filter_bias, mode\n",
    "    \n",
    "class BidirectionalOneShotIterator(object):\n",
    "    def __init__(self, dataloader_head, dataloader_tail):\n",
    "        self.iterator_head = self.one_shot_iterator(dataloader_head)\n",
    "        self.iterator_tail = self.one_shot_iterator(dataloader_tail)\n",
    "        self.step = 0\n",
    "        \n",
    "    def __next__(self):\n",
    "        self.step += 1\n",
    "        if self.step % 2 == 0:\n",
    "            data = next(self.iterator_head)\n",
    "        else:\n",
    "            data = next(self.iterator_tail)\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def one_shot_iterator(dataloader):\n",
    "        while True:\n",
    "            for data in dataloader:\n",
    "                yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_triple(file_path, entity2id, relation2id):\n",
    "    '''\n",
    "    Read triples and map them into ids.\n",
    "    '''\n",
    "    triples = []\n",
    "    with open(file_path) as fin:\n",
    "        for line in fin:\n",
    "            h, r, t = line.strip().split('\\t')\n",
    "            triples.append((entity2id[h], relation2id[r], entity2id[t]))\n",
    "    return triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nentity = 40943, nrelation=11\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "data_path = \"wn18rr\"\n",
    "with open(os.path.join(data_path, 'entities.dict')) as fin:\n",
    "        entity2id = dict()\n",
    "        for line in fin:\n",
    "            eid, entity = line.strip().split('\\t')\n",
    "            entity2id[entity] = int(eid)\n",
    "\n",
    "with open(os.path.join(data_path, 'relations.dict')) as fin:\n",
    "    relation2id = dict()\n",
    "    for line in fin:\n",
    "        rid, relation = line.strip().split('\\t')\n",
    "        relation2id[relation] = int(rid)\n",
    "\n",
    "nentity = len(entity2id)\n",
    "nrelation = len(relation2id)\n",
    "print(f\"nentity = {nentity}, nrelation={nrelation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_training triples = 86835\n",
      "n_validation triples = 3034\n",
      "n_test triples = 3134\n"
     ]
    }
   ],
   "source": [
    "train_triples = read_triple(os.path.join(data_path, 'train.txt'), entity2id, relation2id)\n",
    "valid_triples = read_triple(os.path.join(data_path, 'valid.txt'), entity2id, relation2id)\n",
    "test_triples = read_triple(os.path.join(data_path, 'test.txt'), entity2id, relation2id)\n",
    "print(f\"n_training triples = {len(train_triples)}\")\n",
    "print(f\"n_validation triples = {len(valid_triples)}\")\n",
    "print(f\"n_test triples = {len(test_triples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_true_triples = train_triples + valid_triples + test_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create two data loaders, one for the head entities and one for the tail entities, using the DataLoader class above. \n",
    "# train_dataloader_head = \n",
    "# train_dataloader_tail = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = BidirectionalOneShotIterator(train_dataloader_head, train_dataloader_tail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Model Implementation (20 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS BLOCK \n",
    "class KGEModel(nn.Module):\n",
    "    def __init__(self, model_name, nentity, nrelation, hidden_dim, gamma, \n",
    "                 double_entity_embedding=False, double_relation_embedding=False):\n",
    "        super(KGEModel, self).__init__()\n",
    "        self.model_name = model_name\n",
    "        self.nentity = nentity\n",
    "        self.nrelation = nrelation\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.epsilon = 2.0\n",
    "        \n",
    "        self.gamma = nn.Parameter(\n",
    "            torch.Tensor([gamma]), \n",
    "            requires_grad=False\n",
    "        )\n",
    "        \n",
    "        self.embedding_range = nn.Parameter(\n",
    "            torch.Tensor([(self.gamma.item() + self.epsilon) / hidden_dim]), \n",
    "            requires_grad=False\n",
    "        )\n",
    "        \n",
    "        self.entity_dim = hidden_dim*2 if double_entity_embedding else hidden_dim\n",
    "        self.relation_dim = hidden_dim*2 if double_relation_embedding else hidden_dim\n",
    "\n",
    "        # shallow embedding of size nentity by entity_dim\n",
    "        self.entity_embedding = nn.Parameter(torch.zeros(nentity, self.entity_dim))\n",
    "        nn.init.uniform_(\n",
    "            tensor=self.entity_embedding, \n",
    "            a=-self.embedding_range.item(), \n",
    "            b=self.embedding_range.item()\n",
    "        )\n",
    "        \n",
    "        self.relation_embedding = nn.Parameter(torch.zeros(nrelation, self.relation_dim))\n",
    "        nn.init.uniform_(\n",
    "            tensor=self.relation_embedding, \n",
    "            a=-self.embedding_range.item(), \n",
    "            b=self.embedding_range.item()\n",
    "        )\n",
    "        \n",
    "    def forward(self, sample, mode='single'):\n",
    "        '''\n",
    "        Forward function that calculate the score of a batch of triples.\n",
    "        In the 'single' mode, sample is a batch of triple.\n",
    "        In the 'head-batch' or 'tail-batch' mode, sample consists two part.\n",
    "        The first part is usually the positive sample.\n",
    "        And the second part is the entities in the negative samples.\n",
    "        Because negative samples and positive samples usually share two elements \n",
    "        in their triple ((head, relation) or (relation, tail)).\n",
    "        '''\n",
    "\n",
    "        if mode == 'single':\n",
    "            batch_size, negative_sample_size = sample.size(0), 1\n",
    "            \n",
    "            head = torch.index_select(\n",
    "                self.entity_embedding, \n",
    "                dim=0, \n",
    "                index=sample[:,0]\n",
    "            ).unsqueeze(1)\n",
    "            \n",
    "            relation = torch.index_select(\n",
    "                self.relation_embedding, \n",
    "                dim=0, \n",
    "                index=sample[:,1]\n",
    "            ).unsqueeze(1)\n",
    "            \n",
    "            tail = torch.index_select(\n",
    "                self.entity_embedding, \n",
    "                dim=0, \n",
    "                index=sample[:,2]\n",
    "            ).unsqueeze(1)\n",
    "            \n",
    "        elif mode == 'head-batch':\n",
    "            tail_part, head_part = sample\n",
    "            batch_size, negative_sample_size = head_part.size(0), head_part.size(1)\n",
    "            \n",
    "            head = torch.index_select(\n",
    "                self.entity_embedding, \n",
    "                dim=0, \n",
    "                index=head_part.view(-1)\n",
    "            ).view(batch_size, negative_sample_size, -1)\n",
    "            \n",
    "            relation = torch.index_select(\n",
    "                self.relation_embedding, \n",
    "                dim=0, \n",
    "                index=tail_part[:, 1]\n",
    "            ).unsqueeze(1)\n",
    "            \n",
    "            tail = torch.index_select(\n",
    "                self.entity_embedding, \n",
    "                dim=0, \n",
    "                index=tail_part[:, 2]\n",
    "            ).unsqueeze(1)\n",
    "            \n",
    "        elif mode == 'tail-batch':\n",
    "            head_part, tail_part = sample\n",
    "            batch_size, negative_sample_size = tail_part.size(0), tail_part.size(1)\n",
    "            \n",
    "            head = torch.index_select(\n",
    "                self.entity_embedding, \n",
    "                dim=0, \n",
    "                index=head_part[:, 0]\n",
    "            ).unsqueeze(1)\n",
    "            \n",
    "            relation = torch.index_select(\n",
    "                self.relation_embedding,\n",
    "                dim=0,\n",
    "                index=head_part[:, 1]\n",
    "            ).unsqueeze(1)\n",
    "            \n",
    "            tail = torch.index_select(\n",
    "                self.entity_embedding, \n",
    "                dim=0, \n",
    "                index=tail_part.view(-1)\n",
    "            ).view(batch_size, negative_sample_size, -1)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError('mode %s not supported' % mode)\n",
    "            \n",
    "        model_func = {\n",
    "            'TransE': self.TransE,\n",
    "            'DistMult': self.DistMult,\n",
    "            'RotatE': self.RotatE,\n",
    "        }\n",
    "        \n",
    "        if self.model_name in model_func:\n",
    "            score = model_func[self.model_name](head, relation, tail, mode)\n",
    "        else:\n",
    "            raise ValueError('model %s not supported' % self.model_name)\n",
    "\n",
    "\n",
    "        # rotate E \n",
    "        def RotatE(self, head, relation, tail, mode):\n",
    "            pi = 3.14159265358979323846\n",
    "            \n",
    "            re_head, im_head = torch.chunk(head, 2, dim=2)\n",
    "            re_tail, im_tail = torch.chunk(tail, 2, dim=2)\n",
    "    \n",
    "            #Make phases of relations uniformly distributed in [-pi, pi]\n",
    "    \n",
    "            phase_relation = relation/(self.embedding_range.item()/pi)\n",
    "    \n",
    "            re_relation = torch.cos(phase_relation)\n",
    "            im_relation = torch.sin(phase_relation)\n",
    "    \n",
    "            if mode == 'head-batch':\n",
    "                re_score = re_relation * re_tail + im_relation * im_tail\n",
    "                im_score = re_relation * im_tail - im_relation * re_tail\n",
    "                re_score = re_score - re_head\n",
    "                im_score = im_score - im_head\n",
    "            else:\n",
    "                re_score = re_head * re_relation - im_head * im_relation\n",
    "                im_score = re_head * im_relation + im_head * re_relation\n",
    "                re_score = re_score - re_tail\n",
    "                im_score = im_score - im_tail\n",
    "    \n",
    "            score = torch.stack([re_score, im_score], dim = 0)\n",
    "            score = score.norm(dim = 0)\n",
    "    \n",
    "            score = self.gamma.item() - score.sum(dim = 2)\n",
    "            return score\n",
    "\n",
    "        def TransE(self, head, relation, tail, mode):\n",
    "            \"\"\"\n",
    "            TODO: implement the transE score \n",
    "            head, relation, tail are three embedding vectors \n",
    "            mode can be head-batch or tail-batch\n",
    "            \"\"\"\n",
    "            return score\n",
    "\n",
    "        def DistMult(self, head, relation, tail, mode):\n",
    "            \"\"\"\n",
    "            TODO: implement the transE score \n",
    "            head, relation, tail are three embedding vectors \n",
    "            mode can be head-batch or tail-batch\n",
    "            \"\"\"\n",
    "            return score\n",
    "        \n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TransE (10 pts) \n",
    "\n",
    "Implement a TransE method to be used as the `model_func` in the KGModel class above: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistMult (10 pts) \n",
    "Implement DistMult to be used by KGModel class above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Training, Validation, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True # if you are on colab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, train_iterator):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        positive_sample, negative_sample, _, mode = next(train_iterator)\n",
    "        if cuda:\n",
    "            positive_sample = positive_sample.cuda()\n",
    "            negative_sample = negative_sample.cuda()\n",
    "        # loss computation         \n",
    "        negative_score = model((positive_sample, negative_sample), mode=mode)\n",
    "        negative_score = F.logsigmoid(-negative_score).mean(dim = 1)\n",
    "        positive_score = model(positive_sample)\n",
    "        positive_score = F.logsigmoid(positive_score).squeeze(dim = 1)\n",
    "        positive_sample_loss = - positive_score.mean()\n",
    "        negative_sample_loss = - negative_score.mean()\n",
    "        loss = (positive_sample_loss + negative_sample_loss)/2\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        log = {\n",
    "            'positive_sample_loss': positive_sample_loss.item(),\n",
    "            'negative_sample_loss': negative_sample_loss.item(),\n",
    "            'loss': loss.item()\n",
    "        }\n",
    "\n",
    "        return log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation and MRR (10 pts)\n",
    "\n",
    "The Mean Reciprocal Rank (MRR) is the usual choice to evaluate the result of knowledge graph embedding. It has the formula: \n",
    "$$\n",
    "MRR + \\frac{1}{|Q|}\\sum_{i=1}^{|Q|} \\frac{1}{rank_i}\n",
    "$$\n",
    "where $Q$ is the set of queries, and rank is defined as the order of similarity, defined by the score in the KG embedding loss. Larger score corresponds to higher rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model, test_triples, all_true_triples):    \n",
    "    model.eval()\n",
    "\n",
    "    # TODO: create two test loaders one for head one for tail \n",
    "    # set necessary hyperparameters, including batch size \n",
    "    \n",
    "    # test_dataloader_head = DataLoader(\n",
    "    # test_dataloader_tail = DataLoader( \n",
    "    \n",
    "    test_dataset_list = [test_dataloader_head, test_dataloader_tail]\n",
    "    logs = [] \n",
    "    step = 0\n",
    "    test_log_steps = 10\n",
    "    total_steps = sum([len(dataset) for dataset in test_dataset_list])\n",
    "    with torch.no_grad():\n",
    "        for test_dataset in test_dataset_list:\n",
    "            for positive_sample, negative_sample, filter_bias, mode in test_dataset:\n",
    "                if cuda:\n",
    "                    positive_sample = positive_sample.cuda()\n",
    "                    negative_sample = negative_sample.cuda()\n",
    "                    filter_bias = filter_bias.cuda()\n",
    "\n",
    "                batch_size = positive_sample.size(0)\n",
    "\n",
    "                score = model((positive_sample, negative_sample), mode)\n",
    "                score += filter_bias\n",
    "                argsort = torch.argsort(score, dim = 1, descending=True)\n",
    "                if mode == 'head-batch':\n",
    "                    positive_arg = positive_sample[:, 0]\n",
    "                elif mode == 'tail-batch':\n",
    "                    positive_arg = positive_sample[:, 2]\n",
    "                else:\n",
    "                    raise ValueError('mode %s not supported' % mode)\n",
    "                for i in range(batch_size):\n",
    "                    ranking = (argsort[i, :] == positive_arg[i]).nonzero()\n",
    "                    assert ranking.size(0) == 1\n",
    "\n",
    "                    ranking = 1 + ranking.item()\n",
    "                    logs.append({\n",
    "                        'MRR': 1.0/ranking,\n",
    "                        'MR': float(ranking),\n",
    "                        'HITS@1': 1.0 if ranking <= 1 else 0.0,\n",
    "                        'HITS@3': 1.0 if ranking <= 3 else 0.0,\n",
    "                        'HITS@10': 1.0 if ranking <= 10 else 0.0,\n",
    "                    })\n",
    "                if step % test_log_steps == 0:\n",
    "                    print('Evaluating the model... (%d/%d)' % (step, total_steps))\n",
    "\n",
    "                step += 1\n",
    "    metrics = {}\n",
    "    for metric in logs[0].keys():\n",
    "        metrics[metric] = sum([log[metric] for log in logs])/len(logs)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Loop (20 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: handpick hyperparameters for optimization, together with the optimizer\n",
    "# then initialize 3 models, one for TransE, one for DistMult, one for RotateE \n",
    "max_steps = 2000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_steps, kge_model, optimizer):\n",
    "    training_logs = [] \n",
    "    for step in range(0, max_steps): \n",
    "        log = train_step(kge_model, optimizer, train_iterator)\n",
    "        training_logs.append(log)\n",
    "        if step % 200 == 0:\n",
    "            metrics = test_step(kge_model, valid_triples, all_true_triples)\n",
    "            print(f\"step = {step}\")\n",
    "            print(metrics)\n",
    "    return kge_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train the three models separately \n",
    "train_model(max_steps=max_steps, kge_model=kge_model, optimizer=optimizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: evaluate the trained model on the test triples and report the performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
